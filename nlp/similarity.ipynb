{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "# key libs\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import glob\n",
    "import codecs\n",
    "\n",
    "# nlp libs\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "# processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# LDA\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "\n",
    "# bring in my pickled vectorizers\n",
    "import pickle\n",
    "import dill\n",
    "\n",
    "from nltk import SnowballStemmer\n",
    "from nltk import PorterStemmer\n",
    "from nltk import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSEED = 0\n",
    "bow = 'tfid' # tf,tfid\n",
    "stem_type = 'lemma' # snow, lemma\n",
    "n_gram = '1gm' # 1gm or 2gm\n",
    "topic_model = 'nmf' #lda, nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_link = '../data/samples/fifty_shades.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. PIPELINE 1 - vectorize and topic model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open dill and wordnet_lemmatizer / snowball\n",
    "vectorizer = dill.load(open('../data/vectors/'+bow+'_vectorizer_'+ stem_type + '_' + str(n_gram), 'rb'))\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "snow = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = vectorizer.transform([file_link])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dill.load(open('../data/vectors/'+ topic_model +'_'+ stem_type + '_' + n_gram,'rb'))\n",
    "topic_vector = model.transform(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "      <th>topic_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029896</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_1   topic_2   topic_3   topic_4  topic_5   topic_6  topic_7  \\\n",
       "0  0.029896  0.001828  0.003948  0.003178      0.0  0.001237      0.0   \n",
       "\n",
       "    topic_8  topic_9  topic_10  topic_11  topic_12  topic_13  topic_14  \\\n",
       "0  0.000559      0.0  0.010945       0.0       0.0   0.00205       0.0   \n",
       "\n",
       "   topic_15  \n",
       "0  0.005529  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# place in panda for easy manipulation\n",
    "df_excerpt_a = pd.DataFrame(topic_vector, columns=['topic_'+ str(i)for i in range(1,16)])\n",
    "df_excerpt_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PIPELINE 2 - sentiment analysis and word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk.tokenize import sent_tokenize\n",
    "file=open(file_link)\n",
    "t=file.read()\n",
    "book_excerpt = TextBlob(t)\n",
    "word_count = len(book_excerpt.words)\n",
    "sentence_count =len(book_excerpt.sentences)\n",
    "avg_len = word_count/sentence_count\n",
    "sentiment_excerpt = [[word_count,sentence_count,avg_len,book_excerpt.sentiment[0],book_excerpt.sentiment[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[590, 47, 12.553191489361701, 0.007202380952380952, 0.4518614718614719]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_excerpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excerpt_b = pd.DataFrame(sentiment_excerpt, \\\n",
    "                            columns = ['word_count','sentence_count','sentence_length','polarity','subjectivity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>590</td>\n",
       "      <td>47</td>\n",
       "      <td>12.553191</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.451861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  sentence_count  sentence_length  polarity  subjectivity\n",
       "0         590              47        12.553191  0.007202      0.451861"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_excerpt_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excerpt = pd.concat([df_excerpt_a,df_excerpt_b], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029896</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005529</td>\n",
       "      <td>590</td>\n",
       "      <td>47</td>\n",
       "      <td>12.553191</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.451861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_1   topic_2   topic_3   topic_4  topic_5   topic_6  topic_7  \\\n",
       "0  0.029896  0.001828  0.003948  0.003178      0.0  0.001237      0.0   \n",
       "\n",
       "    topic_8  topic_9  topic_10  topic_11  topic_12  topic_13  topic_14  \\\n",
       "0  0.000559      0.0  0.010945       0.0       0.0   0.00205       0.0   \n",
       "\n",
       "   topic_15  word_count  sentence_count  sentence_length  polarity  \\\n",
       "0  0.005529         590              47        12.553191  0.007202   \n",
       "\n",
       "   subjectivity  \n",
       "0      0.451861  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_excerpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranform\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "# log transform the counts \n",
    "column_names_to_log_1 = ['word_count', 'sentence_count', 'sentence_length']\n",
    "\n",
    "df_excerpt.loc[:,column_names_to_log_1] = df_excerpt.loc[:,column_names_to_log_1].apply(np.log)\n",
    "\n",
    "\n",
    "# normalize subjectivity and polarity\n",
    "column_names_to_normalize = ['subjectivity', 'polarity']\n",
    "\n",
    "# load the scaler \n",
    "min_max_scaler = dill.load(open('../data/vectors/scaler','rb'))\n",
    "\n",
    "x = df_excerpt[column_names_to_normalize].values\n",
    "x_scaled = min_max_scaler.transform(x) # only transform\n",
    "df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = df_excerpt.index)\n",
    "df_excerpt[column_names_to_normalize] = df_temp\n",
    "\n",
    "# log transform topics\n",
    "df_excerpt.loc[:,'topic_1':'topic_15'] = df_excerpt.loc[:,'topic_1':'topic_15'].apply(np.exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.030348</td>\n",
       "      <td>1.001829</td>\n",
       "      <td>1.003956</td>\n",
       "      <td>1.003183</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.001237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.011005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.002052</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.005544</td>\n",
       "      <td>6.380123</td>\n",
       "      <td>3.850148</td>\n",
       "      <td>2.529975</td>\n",
       "      <td>0.227907</td>\n",
       "      <td>0.393448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_1   topic_2   topic_3   topic_4  topic_5   topic_6  topic_7  \\\n",
       "0  1.030348  1.001829  1.003956  1.003183      1.0  1.001237      1.0   \n",
       "\n",
       "    topic_8  topic_9  topic_10  topic_11  topic_12  topic_13  topic_14  \\\n",
       "0  1.000559      1.0  1.011005       1.0       1.0  1.002052       1.0   \n",
       "\n",
       "   topic_15  word_count  sentence_count  sentence_length  polarity  \\\n",
       "0  1.005544    6.380123        3.850148         2.529975  0.227907   \n",
       "\n",
       "   subjectivity  \n",
       "0      0.393448  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_excerpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_title</th>\n",
       "      <th>author_name</th>\n",
       "      <th>book_location</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Behind the Beyond</td>\n",
       "      <td>Stephen Leacock</td>\n",
       "      <td>../data/gutenberg/Stephen Leacock___Behind the...</td>\n",
       "      <td>1.050991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.013402</td>\n",
       "      <td>1.031533</td>\n",
       "      <td>1.098676</td>\n",
       "      <td>1.000042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.024405</td>\n",
       "      <td>1.016348</td>\n",
       "      <td>1.037875</td>\n",
       "      <td>10.312314</td>\n",
       "      <td>7.719130</td>\n",
       "      <td>2.593184</td>\n",
       "      <td>0.463344</td>\n",
       "      <td>0.438980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tommy and Co</td>\n",
       "      <td>Jerome Klapka Jerome</td>\n",
       "      <td>../data/gutenberg/Jerome Klapka Jerome___Tommy...</td>\n",
       "      <td>1.002099</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.008128</td>\n",
       "      <td>1.075021</td>\n",
       "      <td>1.031305</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.280568</td>\n",
       "      <td>1.000047</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.936636</td>\n",
       "      <td>8.395477</td>\n",
       "      <td>2.541159</td>\n",
       "      <td>0.481264</td>\n",
       "      <td>0.534175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Winsome Winnie and other New Nonsense Novels</td>\n",
       "      <td>Stephen Leacock</td>\n",
       "      <td>../data/gutenberg/Stephen Leacock___Winsome Wi...</td>\n",
       "      <td>1.060401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.011625</td>\n",
       "      <td>1.012453</td>\n",
       "      <td>1.114378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.014051</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.004718</td>\n",
       "      <td>1.016062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.587266</td>\n",
       "      <td>8.020270</td>\n",
       "      <td>2.566996</td>\n",
       "      <td>0.506857</td>\n",
       "      <td>0.488050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Moccasin Ranch</td>\n",
       "      <td>Hamlin Garland</td>\n",
       "      <td>../data/gutenberg/Hamlin Garland___The Moccasi...</td>\n",
       "      <td>1.048025</td>\n",
       "      <td>1.000477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.021319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.003149</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.023535</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.008584</td>\n",
       "      <td>9.817221</td>\n",
       "      <td>7.224753</td>\n",
       "      <td>2.592468</td>\n",
       "      <td>0.397930</td>\n",
       "      <td>0.594432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Three Ghost Stories</td>\n",
       "      <td>Charles Dickens</td>\n",
       "      <td>../data/gutenberg/Charles Dickens___Three Ghos...</td>\n",
       "      <td>1.056361</td>\n",
       "      <td>1.001288</td>\n",
       "      <td>1.024470</td>\n",
       "      <td>1.011103</td>\n",
       "      <td>1.133930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.008089</td>\n",
       "      <td>...</td>\n",
       "      <td>1.030547</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.005419</td>\n",
       "      <td>9.960860</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>3.053105</td>\n",
       "      <td>0.404810</td>\n",
       "      <td>0.465239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     book_title           author_name  \\\n",
       "0                             Behind the Beyond       Stephen Leacock   \n",
       "1                                  Tommy and Co  Jerome Klapka Jerome   \n",
       "2  Winsome Winnie and other New Nonsense Novels       Stephen Leacock   \n",
       "3                            The Moccasin Ranch        Hamlin Garland   \n",
       "4                           Three Ghost Stories       Charles Dickens   \n",
       "\n",
       "                                       book_location   topic_1   topic_2  \\\n",
       "0  ../data/gutenberg/Stephen Leacock___Behind the...  1.050991  1.000000   \n",
       "1  ../data/gutenberg/Jerome Klapka Jerome___Tommy...  1.002099  1.000000   \n",
       "2  ../data/gutenberg/Stephen Leacock___Winsome Wi...  1.060401  1.000000   \n",
       "3  ../data/gutenberg/Hamlin Garland___The Moccasi...  1.048025  1.000477   \n",
       "4  ../data/gutenberg/Charles Dickens___Three Ghos...  1.056361  1.001288   \n",
       "\n",
       "    topic_3   topic_4   topic_5   topic_6   topic_7      ...       topic_11  \\\n",
       "0  1.013402  1.031533  1.098676  1.000042  1.000000      ...       1.000000   \n",
       "1  1.008128  1.075021  1.031305  1.000000  1.000000      ...       1.000000   \n",
       "2  1.011625  1.012453  1.114378  1.000000  1.014051      ...       1.000000   \n",
       "3  1.000000  1.021319  1.000000  1.000000  1.003149      ...       1.000000   \n",
       "4  1.024470  1.011103  1.133930  1.000000  1.008089      ...       1.030547   \n",
       "\n",
       "   topic_12  topic_13  topic_14  topic_15  word_count  sentence_count  \\\n",
       "0  1.000000  1.024405  1.016348  1.037875   10.312314        7.719130   \n",
       "1  1.000000  1.280568  1.000047  1.000000   10.936636        8.395477   \n",
       "2  1.004718  1.016062  1.000000  1.000000   10.587266        8.020270   \n",
       "3  1.023535  1.000000  1.000000  1.008584    9.817221        7.224753   \n",
       "4  1.000000  1.000000  1.000000  1.005419    9.960860        6.907755   \n",
       "\n",
       "   sentence_length  polarity  subjectivity  \n",
       "0         2.593184  0.463344      0.438980  \n",
       "1         2.541159  0.481264      0.534175  \n",
       "2         2.566996  0.506857      0.488050  \n",
       "3         2.592468  0.397930      0.594432  \n",
       "4         3.053105  0.404810      0.465239  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the corpus vector from train\n",
    "corpus = pd.read_csv('../data/final_train.csv')\n",
    "corpus = corpus.drop(columns ='Unnamed: 0')\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to drop before finding similarity\n",
    "drop_cols =['word_count','sentence_count']\n",
    "corpus = corpus.drop(columns =drop_cols)\n",
    "df_excerpt = df_excerpt.drop(columns = drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2428, 21)\n",
      "(1, 18)\n"
     ]
    }
   ],
   "source": [
    "print(corpus.shape)\n",
    "print(df_excerpt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape em up to numpy arrays\n",
    "given_excerpt = np.array(df_excerpt)\n",
    "search_in = np.array(corpus.iloc[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 18)\n",
      "(2428, 18)\n"
     ]
    }
   ],
   "source": [
    "print(given_excerpt.shape)\n",
    "print(search_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "results = cosine_similarity(search_in, given_excerpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.999788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "1793  0.999788"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_me = pd.DataFrame(results).sort_values(0, ascending=False).head(1)\n",
    "show_me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Well, The Lady of the Barge and Others, Part 4 by William Wymark Jacobs'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = corpus.iloc[list(show_me.index),0:2].values\n",
    "similar_book = title[0][0] + ' by '+ title[0][1]\n",
    "similar_book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 shades of gray<br>\n",
    "Anna Christie\tby Eugene O\t<br>\n",
    "Anna Christie is the story of a former prostitute who falls in love, but runs into difficulty in turning her life around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Blue Djinn of Babylon<br>\n",
    "The Parasite\tSir Arthur Conan Doyle\t<br>\n",
    "The Parasite makes use of a form of mind control similar to the mesmerism of the Victorian era; it works on some hosts but not others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
