{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "# key libs\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import glob\n",
    "import codecs\n",
    "\n",
    "# nlp libs\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "# processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# LDA\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "\n",
    "# bring in my pickled vectorizers\n",
    "import pickle\n",
    "import dill\n",
    "\n",
    "from nltk import SnowballStemmer\n",
    "from nltk import PorterStemmer\n",
    "from nltk import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSEED = 0\n",
    "bow = 'tf' # tf,tfid\n",
    "stem_type = 'lemma' # snow, lemma\n",
    "n_gram = '1gm' # 1gm or 2gm\n",
    "topic_model = 'lda' #lda, nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_link = '../data/samples/fifty_shades.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. PIPELINE 1 - vectorize and topic model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open dill and wordnet_lemmatizer / snowball\n",
    "vectorizer = dill.load(open('../data/vectors/'+bow+'_vectorizer_'+ stem_type + '_' + str(n_gram), 'rb'))\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "snow = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = vectorizer.transform([file_link])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dill.load(open('../data/vectors/'+ topic_model +'_'+ stem_type + '_' + n_gram,'rb'))\n",
    "topic_vector = model.transform(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.192501</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.52183</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.033007</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.099826</td>\n",
       "      <td>0.146884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_1   topic_2   topic_3   topic_4   topic_5   topic_6   topic_7  \\\n",
       "0  0.000397  0.000397  0.000397  0.192501  0.000397  0.000397  0.000397   \n",
       "\n",
       "    topic_8  topic_9  topic_10  topic_11  topic_12  topic_13  topic_14  \\\n",
       "0  0.000397  0.52183  0.000397  0.000397  0.000397  0.000397  0.000397   \n",
       "\n",
       "   topic_15  topic_16  topic_17  topic_18  topic_19  topic_20  \n",
       "0  0.033007  0.000397  0.000397  0.000397  0.099826  0.146884  "
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# place in panda for easy manipulation\n",
    "df_excerpt_a = pd.DataFrame(topic_vector, columns=['topic_'+ str(i)for i in range(1,21)])\n",
    "df_excerpt_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PIPELINE 2 - sentiment analysis and word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk.tokenize import sent_tokenize\n",
    "file=open(file_link)\n",
    "t=file.read()\n",
    "book_excerpt = TextBlob(t)\n",
    "word_count = len(book_excerpt.words)\n",
    "sentence_count =len(book_excerpt.sentences)\n",
    "avg_len = word_count/sentence_count\n",
    "sentiment_excerpt = [[word_count,sentence_count,avg_len,book_excerpt.sentiment[0],book_excerpt.sentiment[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[590, 47, 12.553191489361701, 0.007202380952380952, 0.4518614718614719]]"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_excerpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excerpt_b = pd.DataFrame(sentiment_excerpt, \\\n",
    "                            columns = ['word_count','sentence_count','sentence_length','polarity','subjectivity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>590</td>\n",
       "      <td>47</td>\n",
       "      <td>12.553191</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.451861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  sentence_count  sentence_length  polarity  subjectivity\n",
       "0         590              47        12.553191  0.007202      0.451861"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_excerpt_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excerpt = pd.concat([df_excerpt_a,df_excerpt_b], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.192501</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.52183</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.099826</td>\n",
       "      <td>0.146884</td>\n",
       "      <td>590</td>\n",
       "      <td>47</td>\n",
       "      <td>12.553191</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.451861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_1   topic_2   topic_3   topic_4   topic_5   topic_6   topic_7  \\\n",
       "0  0.000397  0.000397  0.000397  0.192501  0.000397  0.000397  0.000397   \n",
       "\n",
       "    topic_8  topic_9  topic_10      ...       topic_16  topic_17  topic_18  \\\n",
       "0  0.000397  0.52183  0.000397      ...       0.000397  0.000397  0.000397   \n",
       "\n",
       "   topic_19  topic_20  word_count  sentence_count  sentence_length  polarity  \\\n",
       "0  0.099826  0.146884         590              47        12.553191  0.007202   \n",
       "\n",
       "   subjectivity  \n",
       "0      0.451861  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_excerpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranform\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "# log transform the counts \n",
    "column_names_to_log_1 = ['word_count', 'sentence_count', 'sentence_length']\n",
    "\n",
    "df_excerpt.loc[:,column_names_to_log_1] = df_excerpt.loc[:,column_names_to_log_1].apply(np.log)\n",
    "\n",
    "\n",
    "# normalize subjectivity and polarity\n",
    "column_names_to_normalize = ['subjectivity', 'polarity']\n",
    "\n",
    "# load the scaler \n",
    "min_max_scaler = dill.load(open('../data/vectors/scaler','rb'))\n",
    "\n",
    "x = df_excerpt[column_names_to_normalize].values\n",
    "x_scaled = min_max_scaler.transform(x) # only transform\n",
    "df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = df_excerpt.index)\n",
    "df_excerpt[column_names_to_normalize] = df_temp\n",
    "\n",
    "# log transform topics\n",
    "df_excerpt.loc[:,'topic_1':'topic_20'] = df_excerpt.loc[:,'topic_1':'topic_20'].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.832014</td>\n",
       "      <td>-7.832014</td>\n",
       "      <td>-7.832014</td>\n",
       "      <td>-1.647655</td>\n",
       "      <td>-7.832014</td>\n",
       "      <td>-7.832014</td>\n",
       "      <td>-7.832014</td>\n",
       "      <td>-7.832014</td>\n",
       "      <td>-0.650413</td>\n",
       "      <td>-7.832014</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.832014</td>\n",
       "      <td>-7.832014</td>\n",
       "      <td>-7.832014</td>\n",
       "      <td>-2.304325</td>\n",
       "      <td>-1.918114</td>\n",
       "      <td>6.380123</td>\n",
       "      <td>3.850148</td>\n",
       "      <td>2.529975</td>\n",
       "      <td>0.227907</td>\n",
       "      <td>0.393448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_1   topic_2   topic_3   topic_4   topic_5   topic_6   topic_7  \\\n",
       "0 -7.832014 -7.832014 -7.832014 -1.647655 -7.832014 -7.832014 -7.832014   \n",
       "\n",
       "    topic_8   topic_9  topic_10      ...       topic_16  topic_17  topic_18  \\\n",
       "0 -7.832014 -0.650413 -7.832014      ...      -7.832014 -7.832014 -7.832014   \n",
       "\n",
       "   topic_19  topic_20  word_count  sentence_count  sentence_length  polarity  \\\n",
       "0 -2.304325 -1.918114    6.380123        3.850148         2.529975  0.227907   \n",
       "\n",
       "   subjectivity  \n",
       "0      0.393448  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_excerpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_title</th>\n",
       "      <th>author_name</th>\n",
       "      <th>book_location</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Behind the Beyond</td>\n",
       "      <td>Stephen Leacock</td>\n",
       "      <td>../data/gutenberg/Stephen Leacock___Behind the...</td>\n",
       "      <td>-12.002609</td>\n",
       "      <td>-12.002609</td>\n",
       "      <td>-12.002609</td>\n",
       "      <td>-2.871504</td>\n",
       "      <td>-3.153252</td>\n",
       "      <td>-12.002609</td>\n",
       "      <td>-1.804827</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.601882</td>\n",
       "      <td>-12.002609</td>\n",
       "      <td>-2.533365</td>\n",
       "      <td>-12.002609</td>\n",
       "      <td>-1.715871</td>\n",
       "      <td>10.312314</td>\n",
       "      <td>7.719130</td>\n",
       "      <td>2.593184</td>\n",
       "      <td>0.463344</td>\n",
       "      <td>0.438980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tommy and Co</td>\n",
       "      <td>Jerome Klapka Jerome</td>\n",
       "      <td>../data/gutenberg/Jerome Klapka Jerome___Tommy...</td>\n",
       "      <td>-12.689609</td>\n",
       "      <td>-3.822413</td>\n",
       "      <td>-12.689609</td>\n",
       "      <td>-12.689609</td>\n",
       "      <td>-12.689609</td>\n",
       "      <td>-12.689609</td>\n",
       "      <td>-3.369898</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.813341</td>\n",
       "      <td>-1.759709</td>\n",
       "      <td>-12.689609</td>\n",
       "      <td>-12.689609</td>\n",
       "      <td>-2.188462</td>\n",
       "      <td>10.936636</td>\n",
       "      <td>8.395477</td>\n",
       "      <td>2.541159</td>\n",
       "      <td>0.481264</td>\n",
       "      <td>0.534175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Winsome Winnie and other New Nonsense Novels</td>\n",
       "      <td>Stephen Leacock</td>\n",
       "      <td>../data/gutenberg/Stephen Leacock___Winsome Wi...</td>\n",
       "      <td>-12.318240</td>\n",
       "      <td>-4.697728</td>\n",
       "      <td>-2.575599</td>\n",
       "      <td>-2.319330</td>\n",
       "      <td>-4.822360</td>\n",
       "      <td>-2.884098</td>\n",
       "      <td>-1.610666</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.252721</td>\n",
       "      <td>-3.056927</td>\n",
       "      <td>-12.318240</td>\n",
       "      <td>-12.318240</td>\n",
       "      <td>-2.031256</td>\n",
       "      <td>10.587266</td>\n",
       "      <td>8.020270</td>\n",
       "      <td>2.566996</td>\n",
       "      <td>0.506857</td>\n",
       "      <td>0.488050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Moccasin Ranch</td>\n",
       "      <td>Hamlin Garland</td>\n",
       "      <td>../data/gutenberg/Hamlin Garland___The Moccasi...</td>\n",
       "      <td>-11.631952</td>\n",
       "      <td>-11.631952</td>\n",
       "      <td>-0.884569</td>\n",
       "      <td>-1.790058</td>\n",
       "      <td>-4.037696</td>\n",
       "      <td>-11.631952</td>\n",
       "      <td>-3.698611</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.631952</td>\n",
       "      <td>-11.631952</td>\n",
       "      <td>-11.631952</td>\n",
       "      <td>-11.631952</td>\n",
       "      <td>-4.415382</td>\n",
       "      <td>9.817221</td>\n",
       "      <td>7.224753</td>\n",
       "      <td>2.592468</td>\n",
       "      <td>0.397930</td>\n",
       "      <td>0.594432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Three Ghost Stories</td>\n",
       "      <td>Charles Dickens</td>\n",
       "      <td>../data/gutenberg/Charles Dickens___Three Ghos...</td>\n",
       "      <td>-5.966696</td>\n",
       "      <td>-2.489925</td>\n",
       "      <td>-3.869492</td>\n",
       "      <td>-2.632903</td>\n",
       "      <td>-11.630886</td>\n",
       "      <td>-11.630886</td>\n",
       "      <td>-0.820747</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.382406</td>\n",
       "      <td>-4.625073</td>\n",
       "      <td>-4.409436</td>\n",
       "      <td>-4.862522</td>\n",
       "      <td>-2.233253</td>\n",
       "      <td>9.960860</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>3.053105</td>\n",
       "      <td>0.404810</td>\n",
       "      <td>0.465239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     book_title           author_name  \\\n",
       "0                             Behind the Beyond       Stephen Leacock   \n",
       "1                                  Tommy and Co  Jerome Klapka Jerome   \n",
       "2  Winsome Winnie and other New Nonsense Novels       Stephen Leacock   \n",
       "3                            The Moccasin Ranch        Hamlin Garland   \n",
       "4                           Three Ghost Stories       Charles Dickens   \n",
       "\n",
       "                                       book_location    topic_1    topic_2  \\\n",
       "0  ../data/gutenberg/Stephen Leacock___Behind the... -12.002609 -12.002609   \n",
       "1  ../data/gutenberg/Jerome Klapka Jerome___Tommy... -12.689609  -3.822413   \n",
       "2  ../data/gutenberg/Stephen Leacock___Winsome Wi... -12.318240  -4.697728   \n",
       "3  ../data/gutenberg/Hamlin Garland___The Moccasi... -11.631952 -11.631952   \n",
       "4  ../data/gutenberg/Charles Dickens___Three Ghos...  -5.966696  -2.489925   \n",
       "\n",
       "     topic_3    topic_4    topic_5    topic_6   topic_7      ...       \\\n",
       "0 -12.002609  -2.871504  -3.153252 -12.002609 -1.804827      ...        \n",
       "1 -12.689609 -12.689609 -12.689609 -12.689609 -3.369898      ...        \n",
       "2  -2.575599  -2.319330  -4.822360  -2.884098 -1.610666      ...        \n",
       "3  -0.884569  -1.790058  -4.037696 -11.631952 -3.698611      ...        \n",
       "4  -3.869492  -2.632903 -11.630886 -11.630886 -0.820747      ...        \n",
       "\n",
       "    topic_16   topic_17   topic_18   topic_19  topic_20  word_count  \\\n",
       "0  -2.601882 -12.002609  -2.533365 -12.002609 -1.715871   10.312314   \n",
       "1  -2.813341  -1.759709 -12.689609 -12.689609 -2.188462   10.936636   \n",
       "2  -2.252721  -3.056927 -12.318240 -12.318240 -2.031256   10.587266   \n",
       "3 -11.631952 -11.631952 -11.631952 -11.631952 -4.415382    9.817221   \n",
       "4  -3.382406  -4.625073  -4.409436  -4.862522 -2.233253    9.960860   \n",
       "\n",
       "   sentence_count  sentence_length  polarity  subjectivity  \n",
       "0        7.719130         2.593184  0.463344      0.438980  \n",
       "1        8.395477         2.541159  0.481264      0.534175  \n",
       "2        8.020270         2.566996  0.506857      0.488050  \n",
       "3        7.224753         2.592468  0.397930      0.594432  \n",
       "4        6.907755         3.053105  0.404810      0.465239  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the corpus vector from train\n",
    "corpus = pd.read_csv('../data/final_train.csv')\n",
    "corpus = corpus.drop(columns ='Unnamed: 0')\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to drop before finding similarity\n",
    "drop_cols =['word_count','sentence_count']\n",
    "corpus = corpus.drop(columns =drop_cols)\n",
    "df_excerpt = df_excerpt.drop(columns = drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2428, 26)\n",
      "(1, 23)\n"
     ]
    }
   ],
   "source": [
    "print(corpus.shape)\n",
    "print(df_excerpt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape em up to numpy arrays\n",
    "given_excerpt = np.array(df_excerpt)\n",
    "search_in = np.array(corpus.iloc[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 23)\n",
      "(2428, 23)\n"
     ]
    }
   ],
   "source": [
    "print(given_excerpt.shape)\n",
    "print(search_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "results = cosine_similarity(search_in, given_excerpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>0.973251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>0.961484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>0.961472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2167</th>\n",
       "      <td>0.961386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.961275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "634   0.973251\n",
       "2302  0.961484\n",
       "1650  0.961472\n",
       "2167  0.961386\n",
       "999   0.961275"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_me = pd.DataFrame(results).sort_values(0, ascending=False).head(5)\n",
    "show_me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Anna Christie' 'Eugene O']\n",
      " [\"Bill's Paper Chase, Lady of the Barge and Others, Part 3\"\n",
      "  'William Wymark Jacobs']\n",
      " ['The Persecution of Bob Pretty, Odd Craft, Part 9'\n",
      "  'William Wymark Jacobs']\n",
      " [\"Manners Makyth Man, Ship's Company, Part 12\" 'William Wymark Jacobs']\n",
      " ['Dirty Work, Deep Waters, Part 11' 'William Wymark Jacobs']]\n",
      "Anna Christie by Eugene O\n"
     ]
    }
   ],
   "source": [
    "title = corpus.iloc[list(show_me.index),0:2].values\n",
    "print(title)\n",
    "similar_book = title[0][0] + ' by '+ title[0][1]\n",
    "print(similar_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 shades of gray<br>\n",
    "Anna Christie\tby Eugene O\t<br>\n",
    "Anna Christie is the story of a former prostitute who falls in love, but runs into difficulty in turning her life around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Blue Djinn of Babylon<br>\n",
    "The Parasite\tSir Arthur Conan Doyle\t<br>\n",
    "The Parasite makes use of a form of mind control similar to the mesmerism of the Victorian era; it works on some hosts but not others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
